{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore', category=UserWarning)\n",
    "import optuna\n",
    "import pandas as pd\n",
    "from sklearn import linear_model\n",
    "from sklearn import model_selection\n",
    "import joblib\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se leen los datos y se seleccionan las variables que presentan una diferencia\n",
    "# entre los individuos que presentan estres y los que no\n",
    "data_path = Path(os.getcwd()).parent / \"data\" / \"gold\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loads different feature sets\n",
    "df_manual = pd.read_csv(os.path.join(data_path,'manual_features_train.csv'))\n",
    "X_manual = df_manual.iloc[:,:-1]\n",
    "y_manual = df_manual.iloc[:,-1]\n",
    "\n",
    "df_tfidf = pd.read_csv(os.path.join(data_path,'tfidf_features_train.csv'))\n",
    "X_tfidf = df_tfidf.iloc[:,:-1]\n",
    "y_tfidf = df_tfidf.iloc[:,-1]\n",
    "\n",
    "df_mpnet = pd.read_csv(os.path.join(data_path,'mpnet_features_train.csv'))\n",
    "X_mpnet = df_mpnet.iloc[:,:-1]\n",
    "y_mpnet = df_mpnet.iloc[:,-1]\n",
    "\n",
    "df_distilroberta = pd.read_csv(os.path.join(data_path,'distilroberta_features_train.csv'))\n",
    "X_distilroberta = df_distilroberta.iloc[:,:-1]\n",
    "y_distilroberta = df_distilroberta.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-26 10:51:04,913] A new study created in memory with name: manual_xgboost\n",
      "[I 2024-06-26 10:51:27,957] Trial 0 finished with value: 0.5880252903080302 and parameters: {'learning_rate': 0.02469228085809638, 'max_depth': 337, 'n_estimators': 663}. Best is trial 0 with value: 0.5880252903080302.\n",
      "[I 2024-06-26 10:51:43,863] Trial 1 finished with value: 0.6183945797826244 and parameters: {'learning_rate': 0.003492300301119997, 'max_depth': 295, 'n_estimators': 536}. Best is trial 1 with value: 0.6183945797826244.\n",
      "[I 2024-06-26 10:51:49,826] Trial 2 finished with value: 0.5842940679555225 and parameters: {'learning_rate': 0.25517514284028475, 'max_depth': 168, 'n_estimators': 165}. Best is trial 1 with value: 0.6183945797826244.\n",
      "[I 2024-06-26 10:52:02,792] Trial 3 finished with value: 0.5801584130858497 and parameters: {'learning_rate': 0.12295296782150383, 'max_depth': 380, 'n_estimators': 392}. Best is trial 1 with value: 0.6183945797826244.\n",
      "[I 2024-06-26 10:52:14,352] Trial 4 finished with value: 0.6383471664298358 and parameters: {'learning_rate': 0.0011322671030517012, 'max_depth': 670, 'n_estimators': 488}. Best is trial 4 with value: 0.6383471664298358.\n",
      "[I 2024-06-26 10:52:28,482] Trial 5 finished with value: 0.5830451935146449 and parameters: {'learning_rate': 0.19394965906356532, 'max_depth': 249, 'n_estimators': 597}. Best is trial 4 with value: 0.6383471664298358.\n",
      "[I 2024-06-26 10:52:43,939] Trial 6 finished with value: 0.5848529850257368 and parameters: {'learning_rate': 0.27463556551170754, 'max_depth': 290, 'n_estimators': 733}. Best is trial 4 with value: 0.6383471664298358.\n",
      "[I 2024-06-26 10:52:59,047] Trial 7 finished with value: 0.5837375565507953 and parameters: {'learning_rate': 0.08504377258511339, 'max_depth': 42, 'n_estimators': 476}. Best is trial 4 with value: 0.6383471664298358.\n",
      "[I 2024-06-26 10:53:07,482] Trial 8 finished with value: 0.6857815667263455 and parameters: {'learning_rate': 0.00029743834435345625, 'max_depth': 321, 'n_estimators': 359}. Best is trial 8 with value: 0.6857815667263455.\n",
      "[I 2024-06-26 10:53:22,239] Trial 9 finished with value: 0.589161576815089 and parameters: {'learning_rate': 0.301351442841091, 'max_depth': 136, 'n_estimators': 730}. Best is trial 8 with value: 0.6857815667263455.\n",
      "[I 2024-06-26 10:53:47,438] Trial 10 finished with value: 0.5886044967951429 and parameters: {'learning_rate': 0.025174954651515462, 'max_depth': 608, 'n_estimators': 688}. Best is trial 8 with value: 0.6857815667263455.\n",
      "[I 2024-06-26 10:54:19,745] Trial 11 finished with value: 0.601716362281912 and parameters: {'learning_rate': 0.006698132288523514, 'max_depth': 588, 'n_estimators': 911}. Best is trial 8 with value: 0.6857815667263455.\n",
      "[I 2024-06-26 10:54:40,797] Trial 12 finished with value: 0.675169599595178 and parameters: {'learning_rate': 0.00014136619432258924, 'max_depth': 413, 'n_estimators': 901}. Best is trial 8 with value: 0.6857815667263455.\n",
      "[I 2024-06-26 10:54:59,855] Trial 13 finished with value: 0.584738459032915 and parameters: {'learning_rate': 0.06538576182493434, 'max_depth': 242, 'n_estimators': 627}. Best is trial 8 with value: 0.6857815667263455.\n",
      "[I 2024-06-26 10:55:15,067] Trial 14 finished with value: 0.5842078727942602 and parameters: {'learning_rate': 0.11756211994699663, 'max_depth': 757, 'n_estimators': 531}. Best is trial 8 with value: 0.6857815667263455.\n",
      "[I 2024-06-26 10:55:20,079] Trial 15 finished with value: 0.6179545303161701 and parameters: {'learning_rate': 0.012267560425140734, 'max_depth': 380, 'n_estimators': 170}. Best is trial 8 with value: 0.6857815667263455.\n",
      "[I 2024-06-26 10:55:35,803] Trial 16 finished with value: 0.5792492146774683 and parameters: {'learning_rate': 0.07294535290209508, 'max_depth': 716, 'n_estimators': 552}. Best is trial 8 with value: 0.6857815667263455.\n",
      "[I 2024-06-26 10:55:36,273] Trial 17 finished with value: 0.6880262098607804 and parameters: {'learning_rate': 0.0017374100249365671, 'max_depth': 92, 'n_estimators': 17}. Best is trial 17 with value: 0.6880262098607804.\n",
      "[I 2024-06-26 10:55:51,076] Trial 18 finished with value: 0.5848085136502368 and parameters: {'learning_rate': 0.2652253122142805, 'max_depth': 988, 'n_estimators': 680}. Best is trial 17 with value: 0.6880262098607804.\n",
      "[I 2024-06-26 10:55:57,361] Trial 19 finished with value: 0.6440506089670518 and parameters: {'learning_rate': 0.0014097532430353268, 'max_depth': 177, 'n_estimators': 241}. Best is trial 17 with value: 0.6880262098607804.\n",
      "[I 2024-06-26 10:55:58,068] Trial 20 finished with value: 0.6234245653015537 and parameters: {'learning_rate': 0.042903253594153014, 'max_depth': 37, 'n_estimators': 27}. Best is trial 17 with value: 0.6880262098607804.\n",
      "[I 2024-06-26 10:56:19,355] Trial 21 finished with value: 0.6260174522487288 and parameters: {'learning_rate': 0.0013327933502682093, 'max_depth': 631, 'n_estimators': 812}. Best is trial 17 with value: 0.6880262098607804.\n",
      "[I 2024-06-26 10:56:41,986] Trial 22 finished with value: 0.5869029582856756 and parameters: {'learning_rate': 0.029676207263529757, 'max_depth': 288, 'n_estimators': 631}. Best is trial 17 with value: 0.6880262098607804.\n",
      "[I 2024-06-26 10:57:06,213] Trial 23 finished with value: 0.6824207595540434 and parameters: {'learning_rate': 0.00012115608555803455, 'max_depth': 250, 'n_estimators': 928}. Best is trial 17 with value: 0.6880262098607804.\n",
      "[I 2024-06-26 10:57:07,721] Trial 24 finished with value: 0.6853273346987822 and parameters: {'learning_rate': 0.0016915488443477761, 'max_depth': 710, 'n_estimators': 63}. Best is trial 17 with value: 0.6880262098607804.\n",
      "[I 2024-06-26 10:57:27,901] Trial 25 finished with value: 0.5885797070504855 and parameters: {'learning_rate': 0.020171454004682392, 'max_depth': 771, 'n_estimators': 558}. Best is trial 17 with value: 0.6880262098607804.\n",
      "[I 2024-06-26 10:57:37,242] Trial 26 finished with value: 0.5938719870203439 and parameters: {'learning_rate': 0.047278186280694426, 'max_depth': 27, 'n_estimators': 345}. Best is trial 17 with value: 0.6880262098607804.\n",
      "[I 2024-06-26 10:57:41,482] Trial 27 finished with value: 0.6880262098607804 and parameters: {'learning_rate': 0.00030434384453415485, 'max_depth': 224, 'n_estimators': 160}. Best is trial 17 with value: 0.6880262098607804.\n",
      "[I 2024-06-26 10:58:00,416] Trial 28 finished with value: 0.5853022979426561 and parameters: {'learning_rate': 0.17837420804556225, 'max_depth': 594, 'n_estimators': 918}. Best is trial 17 with value: 0.6880262098607804.\n",
      "[I 2024-06-26 10:58:01,822] Trial 29 finished with value: 0.5874002034228561 and parameters: {'learning_rate': 0.3730084288478299, 'max_depth': 636, 'n_estimators': 42}. Best is trial 17 with value: 0.6880262098607804.\n",
      "[I 2024-06-26 10:58:15,302] Trial 30 finished with value: 0.5878365904271557 and parameters: {'learning_rate': 0.03068856689135662, 'max_depth': 146, 'n_estimators': 369}. Best is trial 17 with value: 0.6880262098607804.\n",
      "[I 2024-06-26 10:58:27,758] Trial 31 finished with value: 0.6369702016279257 and parameters: {'learning_rate': 0.0013703764812568206, 'max_depth': 876, 'n_estimators': 469}. Best is trial 17 with value: 0.6880262098607804.\n",
      "[I 2024-06-26 10:58:30,500] Trial 32 finished with value: 0.6424923099305363 and parameters: {'learning_rate': 0.003206153221470082, 'max_depth': 344, 'n_estimators': 117}. Best is trial 17 with value: 0.6880262098607804.\n",
      "[I 2024-06-26 10:58:56,314] Trial 33 finished with value: 0.6239210758532685 and parameters: {'learning_rate': 0.0015520923478567082, 'max_depth': 890, 'n_estimators': 958}. Best is trial 17 with value: 0.6880262098607804.\n",
      "[I 2024-06-26 10:59:25,599] Trial 34 finished with value: 0.5837754993230112 and parameters: {'learning_rate': 0.029038755805422405, 'max_depth': 910, 'n_estimators': 849}. Best is trial 17 with value: 0.6880262098607804.\n",
      "[I 2024-06-26 10:59:35,919] Trial 35 finished with value: 0.6707868906171083 and parameters: {'learning_rate': 0.00035391994401605647, 'max_depth': 694, 'n_estimators': 390}. Best is trial 17 with value: 0.6880262098607804.\n",
      "[I 2024-06-26 10:59:54,532] Trial 36 finished with value: 0.5873724322371117 and parameters: {'learning_rate': 0.031959305644199375, 'max_depth': 597, 'n_estimators': 579}. Best is trial 17 with value: 0.6880262098607804.\n",
      "[I 2024-06-26 11:00:11,276] Trial 37 finished with value: 0.6740516691006887 and parameters: {'learning_rate': 0.00019820408484725946, 'max_depth': 286, 'n_estimators': 672}. Best is trial 17 with value: 0.6880262098607804.\n",
      "[I 2024-06-26 11:00:32,153] Trial 38 finished with value: 0.581896782682123 and parameters: {'learning_rate': 0.16272872774674002, 'max_depth': 550, 'n_estimators': 891}. Best is trial 17 with value: 0.6880262098607804.\n",
      "[I 2024-06-26 11:01:00,363] Trial 39 finished with value: 0.6230659245826186 and parameters: {'learning_rate': 0.0015174736896993513, 'max_depth': 600, 'n_estimators': 993}. Best is trial 17 with value: 0.6880262098607804.\n",
      "[I 2024-06-26 11:01:18,563] Trial 40 finished with value: 0.644665608037709 and parameters: {'learning_rate': 0.00043195981316517673, 'max_depth': 951, 'n_estimators': 776}. Best is trial 17 with value: 0.6880262098607804.\n",
      "[I 2024-06-26 11:01:41,505] Trial 41 finished with value: 0.5927615410846223 and parameters: {'learning_rate': 0.018065827186519542, 'max_depth': 992, 'n_estimators': 645}. Best is trial 17 with value: 0.6880262098607804.\n",
      "[I 2024-06-26 11:01:44,869] Trial 42 finished with value: 0.5890071962752678 and parameters: {'learning_rate': 0.11692137143260123, 'max_depth': 943, 'n_estimators': 91}. Best is trial 17 with value: 0.6880262098607804.\n",
      "[I 2024-06-26 11:01:55,078] Trial 43 finished with value: 0.5924232632714294 and parameters: {'learning_rate': 0.04124216066166329, 'max_depth': 886, 'n_estimators': 269}. Best is trial 17 with value: 0.6880262098607804.\n",
      "[I 2024-06-26 11:02:12,012] Trial 44 finished with value: 0.6193244573810658 and parameters: {'learning_rate': 0.0025007680411886974, 'max_depth': 55, 'n_estimators': 659}. Best is trial 17 with value: 0.6880262098607804.\n",
      "[I 2024-06-26 11:02:29,443] Trial 45 finished with value: 0.5824841592534877 and parameters: {'learning_rate': 0.14993984466475777, 'max_depth': 154, 'n_estimators': 721}. Best is trial 17 with value: 0.6880262098607804.\n",
      "[I 2024-06-26 11:02:57,574] Trial 46 finished with value: 0.6139244096441528 and parameters: {'learning_rate': 0.0025109634031833155, 'max_depth': 483, 'n_estimators': 973}. Best is trial 17 with value: 0.6880262098607804.\n",
      "[I 2024-06-26 11:03:17,704] Trial 47 finished with value: 0.6803191229903943 and parameters: {'learning_rate': 0.00015406630737806095, 'max_depth': 355, 'n_estimators': 766}. Best is trial 17 with value: 0.6880262098607804.\n",
      "[I 2024-06-26 11:03:35,074] Trial 48 finished with value: 0.6969439796288172 and parameters: {'learning_rate': 0.00011146710861942664, 'max_depth': 903, 'n_estimators': 739}. Best is trial 48 with value: 0.6969439796288172.\n",
      "[I 2024-06-26 11:03:39,158] Trial 49 finished with value: 0.6051648893529946 and parameters: {'learning_rate': 0.040681826636582236, 'max_depth': 310, 'n_estimators': 123}. Best is trial 48 with value: 0.6969439796288172.\n",
      "[I 2024-06-26 11:03:54,187] Trial 50 finished with value: 0.6969439796288172 and parameters: {'learning_rate': 0.00014136619432258924, 'max_depth': 413, 'n_estimators': 584}. Best is trial 48 with value: 0.6969439796288172.\n",
      "[I 2024-06-26 11:04:03,830] Trial 51 finished with value: 0.6381336398287728 and parameters: {'learning_rate': 0.0015520923478567082, 'max_depth': 686, 'n_estimators': 364}. Best is trial 48 with value: 0.6969439796288172.\n",
      "[I 2024-06-26 11:04:09,076] Trial 52 finished with value: 0.6880262098607804 and parameters: {'learning_rate': 0.00019820408484725946, 'max_depth': 144, 'n_estimators': 225}. Best is trial 48 with value: 0.6969439796288172.\n",
      "[I 2024-06-26 11:04:26,268] Trial 53 finished with value: 0.62792591621868 and parameters: {'learning_rate': 0.0015174736896993513, 'max_depth': 55, 'n_estimators': 659}. Best is trial 48 with value: 0.6969439796288172.\n",
      "[I 2024-06-26 11:04:47,217] Trial 54 finished with value: 0.5872044959742575 and parameters: {'learning_rate': 0.029676207263529757, 'max_depth': 600, 'n_estimators': 584}. Best is trial 48 with value: 0.6969439796288172.\n",
      "[I 2024-06-26 11:04:56,283] Trial 55 finished with value: 0.6880262098607804 and parameters: {'learning_rate': 0.00015406630737806095, 'max_depth': 27, 'n_estimators': 345}. Best is trial 48 with value: 0.6969439796288172.\n",
      "[I 2024-06-26 11:05:26,133] Trial 56 finished with value: 0.5869892496723961 and parameters: {'learning_rate': 0.02469228085809638, 'max_depth': 890, 'n_estimators': 958}. Best is trial 48 with value: 0.6969439796288172.\n",
      "[I 2024-06-26 11:05:51,775] Trial 57 finished with value: 0.5819831850170522 and parameters: {'learning_rate': 0.06470154275811306, 'max_depth': 413, 'n_estimators': 901}. Best is trial 48 with value: 0.6969439796288172.\n",
      "[I 2024-06-26 11:06:19,912] Trial 58 finished with value: 0.6139244096441528 and parameters: {'learning_rate': 0.0025109634031833155, 'max_depth': 483, 'n_estimators': 973}. Best is trial 48 with value: 0.6969439796288172.\n",
      "[I 2024-06-26 11:06:24,393] Trial 59 finished with value: 0.6425311266021699 and parameters: {'learning_rate': 0.002215239450057364, 'max_depth': 380, 'n_estimators': 170}. Best is trial 48 with value: 0.6969439796288172.\n",
      "[I 2024-06-26 11:06:25,863] Trial 60 finished with value: 0.6880262098607804 and parameters: {'learning_rate': 0.00012115608555803455, 'max_depth': 891, 'n_estimators': 63}. Best is trial 48 with value: 0.6969439796288172.\n",
      "[I 2024-06-26 11:06:45,041] Trial 61 finished with value: 0.6803191229903943 and parameters: {'learning_rate': 0.00015406630737806095, 'max_depth': 355, 'n_estimators': 766}. Best is trial 48 with value: 0.6969439796288172.\n",
      "[I 2024-06-26 11:06:57,125] Trial 62 finished with value: 0.6638619476911498 and parameters: {'learning_rate': 0.00035391994401605647, 'max_depth': 694, 'n_estimators': 459}. Best is trial 48 with value: 0.6969439796288172.\n",
      "[I 2024-06-26 11:07:01,502] Trial 63 finished with value: 0.6880262098607804 and parameters: {'learning_rate': 0.0001747982215374191, 'max_depth': 380, 'n_estimators': 170}. Best is trial 48 with value: 0.6969439796288172.\n",
      "[I 2024-06-26 11:07:23,374] Trial 64 finished with value: 0.6824207595540434 and parameters: {'learning_rate': 0.00012115608555803455, 'max_depth': 373, 'n_estimators': 928}. Best is trial 48 with value: 0.6969439796288172.\n",
      "[I 2024-06-26 11:07:39,490] Trial 65 finished with value: 0.6090393059581516 and parameters: {'learning_rate': 0.005986779747811524, 'max_depth': 678, 'n_estimators': 545}. Best is trial 48 with value: 0.6969439796288172.\n",
      "[I 2024-06-26 11:07:55,896] Trial 66 finished with value: 0.6870369918004088 and parameters: {'learning_rate': 0.00015406630737806095, 'max_depth': 355, 'n_estimators': 649}. Best is trial 48 with value: 0.6969439796288172.\n",
      "[I 2024-06-26 11:07:57,137] Trial 67 finished with value: 0.6658617530766842 and parameters: {'learning_rate': 0.003089937443471936, 'max_depth': 344, 'n_estimators': 46}. Best is trial 48 with value: 0.6969439796288172.\n",
      "[I 2024-06-26 11:08:02,338] Trial 68 finished with value: 0.7018628148907116 and parameters: {'learning_rate': 0.00035391994401605647, 'max_depth': 304, 'n_estimators': 221}. Best is trial 68 with value: 0.7018628148907116.\n",
      "[I 2024-06-26 11:08:12,810] Trial 69 finished with value: 0.5863756362808923 and parameters: {'learning_rate': 0.31944765587933693, 'max_depth': 670, 'n_estimators': 488}. Best is trial 68 with value: 0.7018628148907116.\n",
      "[I 2024-06-26 11:08:23,463] Trial 70 finished with value: 0.5805594772035334 and parameters: {'learning_rate': 0.14993984466475777, 'max_depth': 136, 'n_estimators': 378}. Best is trial 68 with value: 0.7018628148907116.\n",
      "[I 2024-06-26 11:08:36,446] Trial 71 finished with value: 0.5843346358837743 and parameters: {'learning_rate': 0.08504377258511339, 'max_depth': 42, 'n_estimators': 407}. Best is trial 68 with value: 0.7018628148907116.\n",
      "[I 2024-06-26 11:08:36,871] Trial 72 finished with value: 0.6880262098607804 and parameters: {'learning_rate': 0.0017374100249365671, 'max_depth': 92, 'n_estimators': 17}. Best is trial 68 with value: 0.7018628148907116.\n",
      "[I 2024-06-26 11:08:40,362] Trial 73 finished with value: 0.6625035251599186 and parameters: {'learning_rate': 0.0013327933502682093, 'max_depth': 92, 'n_estimators': 140}. Best is trial 68 with value: 0.7018628148907116.\n",
      "[I 2024-06-26 11:08:47,561] Trial 74 finished with value: 0.6399564550037508 and parameters: {'learning_rate': 0.0016915488443477761, 'max_depth': 483, 'n_estimators': 284}. Best is trial 68 with value: 0.7018628148907116.\n",
      "[I 2024-06-26 11:08:57,090] Trial 75 finished with value: 0.6435810326538803 and parameters: {'learning_rate': 0.0011322671030517012, 'max_depth': 670, 'n_estimators': 369}. Best is trial 68 with value: 0.7018628148907116.\n",
      "[I 2024-06-26 11:09:08,481] Trial 76 finished with value: 0.6413889816666989 and parameters: {'learning_rate': 0.0009872110686535698, 'max_depth': 380, 'n_estimators': 484}. Best is trial 68 with value: 0.7018628148907116.\n",
      "[I 2024-06-26 11:09:32,949] Trial 77 finished with value: 0.6112802904474401 and parameters: {'learning_rate': 0.003492300301119997, 'max_depth': 295, 'n_estimators': 848}. Best is trial 68 with value: 0.7018628148907116.\n",
      "[I 2024-06-26 11:09:34,116] Trial 78 finished with value: 0.6402021809451724 and parameters: {'learning_rate': 0.012267560425140734, 'max_depth': 380, 'n_estimators': 44}. Best is trial 68 with value: 0.7018628148907116.\n",
      "[I 2024-06-26 11:09:46,729] Trial 79 finished with value: 0.6185271843586057 and parameters: {'learning_rate': 0.0043523275736912555, 'max_depth': 310, 'n_estimators': 437}. Best is trial 68 with value: 0.7018628148907116.\n",
      "[I 2024-06-26 11:09:55,120] Trial 80 finished with value: 0.6880262098607804 and parameters: {'learning_rate': 0.00014136619432258924, 'max_depth': 535, 'n_estimators': 359}. Best is trial 68 with value: 0.7018628148907116.\n",
      "[I 2024-06-26 11:10:17,816] Trial 81 finished with value: 0.5981929221933766 and parameters: {'learning_rate': 0.006255232500315874, 'max_depth': 482, 'n_estimators': 739}. Best is trial 68 with value: 0.7018628148907116.\n",
      "[I 2024-06-26 11:10:31,032] Trial 82 finished with value: 0.6166260084983354 and parameters: {'learning_rate': 0.0043288843711009346, 'max_depth': 876, 'n_estimators': 469}. Best is trial 68 with value: 0.7018628148907116.\n",
      "[I 2024-06-26 11:10:40,390] Trial 83 finished with value: 0.6753360528989735 and parameters: {'learning_rate': 0.00035391994401605647, 'max_depth': 588, 'n_estimators': 361}. Best is trial 68 with value: 0.7018628148907116.\n",
      "[I 2024-06-26 11:10:48,785] Trial 84 finished with value: 0.6851927706063444 and parameters: {'learning_rate': 0.00030434384453415485, 'max_depth': 162, 'n_estimators': 359}. Best is trial 68 with value: 0.7018628148907116.\n",
      "[I 2024-06-26 11:10:54,974] Trial 85 finished with value: 0.6438845784342605 and parameters: {'learning_rate': 0.0013327933502682093, 'max_depth': 631, 'n_estimators': 251}. Best is trial 68 with value: 0.7018628148907116.\n",
      "[I 2024-06-26 11:11:15,096] Trial 86 finished with value: 0.6002225361098149 and parameters: {'learning_rate': 0.010718926470074051, 'max_depth': 694, 'n_estimators': 582}. Best is trial 68 with value: 0.7018628148907116.\n",
      "[I 2024-06-26 11:11:17,676] Trial 87 finished with value: 0.6880262098607804 and parameters: {'learning_rate': 0.00015406630737806095, 'max_depth': 355, 'n_estimators': 100}. Best is trial 68 with value: 0.7018628148907116.\n",
      "[I 2024-06-26 11:11:23,321] Trial 88 finished with value: 0.6880262098607804 and parameters: {'learning_rate': 0.00021053499835279932, 'max_depth': 177, 'n_estimators': 241}. Best is trial 68 with value: 0.7018628148907116.\n",
      "[I 2024-06-26 11:11:40,518] Trial 89 finished with value: 0.5887046281373632 and parameters: {'learning_rate': 0.030226148445075224, 'max_depth': 236, 'n_estimators': 488}. Best is trial 68 with value: 0.7018628148907116.\n",
      "[I 2024-06-26 11:12:06,946] Trial 90 finished with value: 0.6226123126741298 and parameters: {'learning_rate': 0.0013703764812568206, 'max_depth': 876, 'n_estimators': 973}. Best is trial 68 with value: 0.7018628148907116.\n",
      "[I 2024-06-26 11:12:38,282] Trial 91 finished with value: 0.6018961845075823 and parameters: {'learning_rate': 0.006698132288523514, 'max_depth': 413, 'n_estimators': 901}. Best is trial 68 with value: 0.7018628148907116.\n",
      "[I 2024-06-26 11:12:52,091] Trial 92 finished with value: 0.6183945797826244 and parameters: {'learning_rate': 0.003492300301119997, 'max_depth': 658, 'n_estimators': 536}. Best is trial 68 with value: 0.7018628148907116.\n",
      "[I 2024-06-26 11:12:55,056] Trial 93 finished with value: 0.6424923099305363 and parameters: {'learning_rate': 0.003206153221470082, 'max_depth': 344, 'n_estimators': 117}. Best is trial 68 with value: 0.7018628148907116.\n",
      "[I 2024-06-26 11:13:06,944] Trial 94 finished with value: 0.5945186224093759 and parameters: {'learning_rate': 0.02469228085809638, 'max_depth': 337, 'n_estimators': 332}. Best is trial 68 with value: 0.7018628148907116.\n",
      "[I 2024-06-26 11:13:26,679] Trial 95 finished with value: 0.6570597344042836 and parameters: {'learning_rate': 0.00029743834435345625, 'max_depth': 321, 'n_estimators': 769}. Best is trial 68 with value: 0.7018628148907116.\n",
      "[I 2024-06-26 11:13:31,534] Trial 96 finished with value: 0.6013299505897695 and parameters: {'learning_rate': 0.03091384201483661, 'max_depth': 224, 'n_estimators': 160}. Best is trial 68 with value: 0.7018628148907116.\n",
      "[I 2024-06-26 11:13:51,840] Trial 97 finished with value: 0.6390078088184551 and parameters: {'learning_rate': 0.000668240364373589, 'max_depth': 256, 'n_estimators': 812}. Best is trial 68 with value: 0.7018628148907116.\n",
      "[I 2024-06-26 11:13:56,759] Trial 98 finished with value: 0.6076211777457777 and parameters: {'learning_rate': 0.031959305644199375, 'max_depth': 600, 'n_estimators': 150}. Best is trial 68 with value: 0.7018628148907116.\n",
      "[I 2024-06-26 11:14:05,984] Trial 99 finished with value: 0.6857815667263455 and parameters: {'learning_rate': 0.00029743834435345625, 'max_depth': 321, 'n_estimators': 359}. Best is trial 68 with value: 0.7018628148907116.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['c:\\\\Users\\\\franc.FJMOYAO\\\\Desktop\\\\Programming Projects\\\\depression_detection\\\\data\\\\gold\\\\manual_xgboost.pkl']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def objective_manual_xgboost(trial):\n",
    "    \n",
    "    lrate = trial.suggest_float(\"learning_rate\", 0.0001, 0.4, log=True)\n",
    "    max_depth = trial.suggest_int(\"max_depth\", 10, 1000)\n",
    "    n_estimators =trial.suggest_int(\"n_estimators\", 10, 1000)\n",
    "    classifier_obj = XGBClassifier(n_estimators=n_estimators, max_depth=max_depth, learning_rate=lrate, \n",
    "                                   objective='binary:logistic',\n",
    "                                   device='cuda')\n",
    "\n",
    "    # Step 3: Scoring method:\n",
    "    score = model_selection.cross_val_score(classifier_obj, X_manual, y_manual, n_jobs=-1, cv=3, scoring=\"f1\")\n",
    "    fscore = score.mean()\n",
    "    return fscore\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\",study_name=\"manual_xgboost\",\n",
    "                             sampler=optuna.samplers.NSGAIISampler())\n",
    "\n",
    "# Adding Attributes to Study\n",
    "study.set_user_attr('contributors', ['Francisco'])\n",
    "study.set_user_attr('dataset', 'Manual')\n",
    "\n",
    "# Store and load using joblib:\n",
    "study_path = os.path.join(data_path,'manual_xgboost.pkl')\n",
    "if not os.path.isfile(study_path):\n",
    "    joblib.dump(study, study_path)\n",
    "\n",
    "study = joblib.load(study_path)\n",
    "\n",
    "study.optimize(objective_manual_xgboost, n_trials=100)\n",
    "joblib.dump(study, study_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-26 12:55:45,012] A new study created in memory with name: tfidf_xgboost\n",
      "[I 2024-06-26 12:57:44,474] Trial 0 finished with value: 0.6931127871885815 and parameters: {'learning_rate': 0.006064090298562169, 'max_depth': 362, 'n_estimators': 339}. Best is trial 0 with value: 0.6931127871885815.\n",
      "[I 2024-06-26 13:03:22,192] Trial 1 finished with value: 0.6749624665992404 and parameters: {'learning_rate': 0.0008923476476256534, 'max_depth': 707, 'n_estimators': 948}. Best is trial 0 with value: 0.6931127871885815.\n",
      "[I 2024-06-26 13:08:00,104] Trial 2 finished with value: 0.7046896080324946 and parameters: {'learning_rate': 0.00014046003573146124, 'max_depth': 400, 'n_estimators': 808}. Best is trial 2 with value: 0.7046896080324946.\n",
      "[I 2024-06-26 13:10:09,090] Trial 3 finished with value: 0.6846548253620962 and parameters: {'learning_rate': 0.0008516260922581012, 'max_depth': 911, 'n_estimators': 366}. Best is trial 2 with value: 0.7046896080324946.\n",
      "[I 2024-06-26 13:13:00,342] Trial 4 finished with value: 0.6916897110987082 and parameters: {'learning_rate': 0.0004150751317948861, 'max_depth': 841, 'n_estimators': 490}. Best is trial 2 with value: 0.7046896080324946.\n",
      "[I 2024-06-26 13:13:27,877] Trial 5 finished with value: 0.6750462259131655 and parameters: {'learning_rate': 0.012628743366165467, 'max_depth': 141, 'n_estimators': 72}. Best is trial 2 with value: 0.7046896080324946.\n",
      "[I 2024-06-26 13:14:05,347] Trial 6 finished with value: 0.7045173629880122 and parameters: {'learning_rate': 0.24836474719853358, 'max_depth': 638, 'n_estimators': 526}. Best is trial 2 with value: 0.7046896080324946.\n",
      "[I 2024-06-26 13:15:07,268] Trial 7 finished with value: 0.6880262098607804 and parameters: {'learning_rate': 0.0001480542998190839, 'max_depth': 784, 'n_estimators': 175}. Best is trial 2 with value: 0.7046896080324946.\n",
      "[I 2024-06-26 13:15:32,550] Trial 8 finished with value: 0.7027436831677676 and parameters: {'learning_rate': 0.006674465667153961, 'max_depth': 6, 'n_estimators': 754}. Best is trial 2 with value: 0.7046896080324946.\n",
      "[I 2024-06-26 13:20:09,322] Trial 9 finished with value: 0.6864915933812107 and parameters: {'learning_rate': 0.002111467876717631, 'max_depth': 879, 'n_estimators': 785}. Best is trial 2 with value: 0.7046896080324946.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['c:\\\\Users\\\\franc.FJMOYAO\\\\Desktop\\\\Programming Projects\\\\depression_detection\\\\data\\\\gold\\\\tfidf_xgboost.pkl']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def objective_tfidf_xgboost(trial):\n",
    "    \n",
    "    lrate = trial.suggest_float(\"learning_rate\", 0.0001, 0.4, log=True)\n",
    "    max_depth = trial.suggest_int(\"max_depth\", 2, 1000)\n",
    "    n_estimators =trial.suggest_int(\"n_estimators\", 2, 1000)\n",
    "    classifier_obj = XGBClassifier(n_estimators=n_estimators, max_depth=max_depth, learning_rate=lrate, \n",
    "                                   objective='binary:logistic',\n",
    "                                   device='cuda')\n",
    "\n",
    "    # Step 3: Scoring method:\n",
    "    score = model_selection.cross_val_score(classifier_obj, X_tfidf, y_tfidf, n_jobs=-1, cv=3, scoring=\"f1\")\n",
    "    fscore = score.mean()\n",
    "    return fscore\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\",study_name=\"tfidf_xgboost\",\n",
    "                             sampler=optuna.samplers.NSGAIISampler())\n",
    "\n",
    "# Adding Attributes to Study\n",
    "study.set_user_attr('contributors', ['Francisco'])\n",
    "study.set_user_attr('dataset', 'tfidf')\n",
    "\n",
    "# Store and load using joblib:\n",
    "study_path = os.path.join(data_path,'tfidf_xgboost.pkl')\n",
    "if not os.path.isfile(study_path):\n",
    "    joblib.dump(study, study_path)\n",
    "\n",
    "study = joblib.load(study_path)\n",
    "\n",
    "study.optimize(objective_tfidf_xgboost, n_trials=10)\n",
    "joblib.dump(study, study_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-26 11:45:00,412] A new study created in memory with name: mpnet_xgboost\n",
      "[I 2024-06-26 11:53:41,949] Trial 0 finished with value: 0.7718134228556068 and parameters: {'learning_rate': 0.003261971368266794, 'max_depth': 870, 'n_estimators': 647}. Best is trial 0 with value: 0.7718134228556068.\n",
      "[I 2024-06-26 12:01:05,975] Trial 1 finished with value: 0.775559456304039 and parameters: {'learning_rate': 0.0029077866359644234, 'max_depth': 778, 'n_estimators': 871}. Best is trial 1 with value: 0.775559456304039.\n",
      "[I 2024-06-26 12:02:22,761] Trial 2 finished with value: 0.7908173821072445 and parameters: {'learning_rate': 0.044360495126544996, 'max_depth': 433, 'n_estimators': 635}. Best is trial 2 with value: 0.7908173821072445.\n",
      "[I 2024-06-26 12:04:00,037] Trial 3 finished with value: 0.7896686009492303 and parameters: {'learning_rate': 0.036987173238199195, 'max_depth': 345, 'n_estimators': 246}. Best is trial 2 with value: 0.7908173821072445.\n",
      "[I 2024-06-26 12:10:07,863] Trial 4 finished with value: 0.7682015605386529 and parameters: {'learning_rate': 0.0014762142869402036, 'max_depth': 688, 'n_estimators': 955}. Best is trial 2 with value: 0.7908173821072445.\n",
      "[I 2024-06-26 12:12:32,333] Trial 5 finished with value: 0.7208198818814239 and parameters: {'learning_rate': 0.0001822157629266806, 'max_depth': 930, 'n_estimators': 336}. Best is trial 2 with value: 0.7908173821072445.\n",
      "[I 2024-06-26 12:19:19,926] Trial 6 finished with value: 0.7204668371099675 and parameters: {'learning_rate': 0.0001168990953138998, 'max_depth': 903, 'n_estimators': 782}. Best is trial 2 with value: 0.7908173821072445.\n",
      "[I 2024-06-26 12:23:09,655] Trial 7 finished with value: 0.7464585559501224 and parameters: {'learning_rate': 0.0008579160351951056, 'max_depth': 861, 'n_estimators': 614}. Best is trial 2 with value: 0.7908173821072445.\n",
      "[I 2024-06-26 12:28:05,514] Trial 8 finished with value: 0.7193330598132799 and parameters: {'learning_rate': 0.0001778531499826587, 'max_depth': 161, 'n_estimators': 565}. Best is trial 2 with value: 0.7908173821072445.\n",
      "[I 2024-06-26 12:36:36,689] Trial 9 finished with value: 0.7959316977100864 and parameters: {'learning_rate': 0.0912770918680834, 'max_depth': 835, 'n_estimators': 728}. Best is trial 9 with value: 0.7959316977100864.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['c:\\\\Users\\\\franc.FJMOYAO\\\\Desktop\\\\Programming Projects\\\\depression_detection\\\\data\\\\gold\\\\mpnet_xgboost.pkl']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def objective_mpnet_xgboost(trial):\n",
    "    \n",
    "    lrate = trial.suggest_float(\"learning_rate\", 0.0001, 0.4, log=True)\n",
    "    max_depth = trial.suggest_int(\"max_depth\", 10, 1000)\n",
    "    n_estimators =trial.suggest_int(\"n_estimators\", 10, 1000)\n",
    "    classifier_obj = XGBClassifier(n_estimators=n_estimators, max_depth=max_depth, learning_rate=lrate, \n",
    "                                   objective='binary:logistic',\n",
    "                                   device='cuda')\n",
    "\n",
    "    # Step 3: Scoring method:\n",
    "    score = model_selection.cross_val_score(classifier_obj, X_mpnet, y_mpnet, n_jobs=-1, cv=3, scoring=\"f1\")\n",
    "    fscore = score.mean()\n",
    "    return fscore\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\",study_name=\"mpnet_xgboost\",\n",
    "                             sampler=optuna.samplers.NSGAIISampler())\n",
    "\n",
    "# Adding Attributes to Study\n",
    "study.set_user_attr('contributors', ['Francisco'])\n",
    "study.set_user_attr('dataset', 'mpnet')\n",
    "\n",
    "# Store and load using joblib:\n",
    "study_path = os.path.join(data_path,'mpnet_xgboost.pkl')   \n",
    "if not os.path.isfile(study_path):\n",
    "    joblib.dump(study, study_path)\n",
    "\n",
    "study = joblib.load(study_path)\n",
    "\n",
    "study.optimize(objective_mpnet_xgboost, n_trials=10)\n",
    "joblib.dump(study, study_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-26 13:21:16,426] A new study created in memory with name: distilroberta_xgboost\n",
      "[I 2024-06-26 13:22:40,800] Trial 0 finished with value: 0.8021432752231589 and parameters: {'learning_rate': 0.18671982240811918, 'max_depth': 782, 'n_estimators': 935}. Best is trial 0 with value: 0.8021432752231589.\n",
      "[I 2024-06-26 13:37:57,128] Trial 1 finished with value: 0.7412384536392022 and parameters: {'learning_rate': 0.0015832746633105547, 'max_depth': 329, 'n_estimators': 466}. Best is trial 0 with value: 0.8021432752231589.\n",
      "[I 2024-06-26 13:43:26,886] Trial 2 finished with value: 0.7397994539181134 and parameters: {'learning_rate': 0.0006192987925892433, 'max_depth': 939, 'n_estimators': 713}. Best is trial 0 with value: 0.8021432752231589.\n",
      "[I 2024-06-26 13:49:54,732] Trial 3 finished with value: 0.7157111067210571 and parameters: {'learning_rate': 0.00010126147272962402, 'max_depth': 944, 'n_estimators': 534}. Best is trial 0 with value: 0.8021432752231589.\n",
      "[I 2024-06-26 13:50:36,635] Trial 4 finished with value: 0.7822881713932838 and parameters: {'learning_rate': 0.03389403602493431, 'max_depth': 577, 'n_estimators': 132}. Best is trial 0 with value: 0.8021432752231589.\n",
      "[I 2024-06-26 13:57:51,862] Trial 5 finished with value: 0.757462140133164 and parameters: {'learning_rate': 0.0016639613862889878, 'max_depth': 780, 'n_estimators': 854}. Best is trial 0 with value: 0.8021432752231589.\n",
      "[I 2024-06-26 14:00:10,113] Trial 6 finished with value: 0.7815323408892186 and parameters: {'learning_rate': 0.00814879452186709, 'max_depth': 532, 'n_estimators': 491}. Best is trial 0 with value: 0.8021432752231589.\n",
      "[I 2024-06-26 14:01:54,782] Trial 7 finished with value: 0.7963024045202117 and parameters: {'learning_rate': 0.09559351401564542, 'max_depth': 101, 'n_estimators': 939}. Best is trial 0 with value: 0.8021432752231589.\n",
      "[I 2024-06-26 14:09:41,200] Trial 8 finished with value: 0.7866444012179232 and parameters: {'learning_rate': 0.0065805691540779575, 'max_depth': 242, 'n_estimators': 795}. Best is trial 0 with value: 0.8021432752231589.\n",
      "[I 2024-06-26 14:13:45,899] Trial 9 finished with value: 0.7339608944682375 and parameters: {'learning_rate': 0.0006695448384675621, 'max_depth': 588, 'n_estimators': 595}. Best is trial 0 with value: 0.8021432752231589.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['c:\\\\Users\\\\franc.FJMOYAO\\\\Desktop\\\\Programming Projects\\\\depression_detection\\\\data\\\\gold\\\\distilroberta_xgboost.pkl']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def objective_distilroberta_xgboost(trial):\n",
    "    \n",
    "    lrate = trial.suggest_float(\"learning_rate\", 0.0001, 0.4, log=True)\n",
    "    max_depth = trial.suggest_int(\"max_depth\", 10, 1000)\n",
    "    n_estimators =trial.suggest_int(\"n_estimators\", 10, 1000)\n",
    "    classifier_obj = XGBClassifier(n_estimators=n_estimators, max_depth=max_depth, learning_rate=lrate, \n",
    "                                   objective='binary:logistic',\n",
    "                                   device='cuda')\n",
    "\n",
    "    # Step 3: Scoring method:\n",
    "    score = model_selection.cross_val_score(classifier_obj, X_distilroberta, y_distilroberta, n_jobs=-1, cv=3, scoring=\"f1\")\n",
    "    fscore = score.mean()\n",
    "    return fscore\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\",study_name=\"distilroberta_xgboost\",\n",
    "                             sampler=optuna.samplers.NSGAIISampler())\n",
    "\n",
    "# Adding Attributes to Study\n",
    "study.set_user_attr('contributors', ['Francisco'])\n",
    "study.set_user_attr('dataset', 'distilroberta')\n",
    "\n",
    "# Store and load using joblib:\n",
    "study_path = os.path.join(data_path,'distilroberta_xgboost.pkl')\n",
    "if not os.path.isfile(study_path):  \n",
    "    joblib.dump(study, study_path)\n",
    "\n",
    "study = joblib.load(study_path)\n",
    "\n",
    "study.optimize(objective_distilroberta_xgboost, n_trials=10)\n",
    "joblib.dump(study, study_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_studies = [os.path.join(data_path,x) for x in os.listdir(data_path) if \"xgboost\" in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_experiments = pd.DataFrame()\n",
    "for study_path in xgboost_studies:\n",
    "    cur_study = joblib.load(study_path)\n",
    "    cur_study_df = cur_study.trials_dataframe()\n",
    "    cur_study_df[\"dataset\"] = cur_study.user_attrs[\"dataset\"]\n",
    "    xgboost_experiments = pd.concat([xgboost_experiments, cur_study_df])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dataset\n",
       "Manual           0.701863\n",
       "distilroberta    0.802143\n",
       "mpnet            0.795932\n",
       "tfidf            0.704690\n",
       "Name: value, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgboost_experiments.groupby(\"dataset\")[\"value\"].max()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
