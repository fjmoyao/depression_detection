{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Proyectos\\TESIS 2024\\depression_detection\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "from pathlib import Path\n",
    "import pandas as pd \n",
    "import re\n",
    "import utils\n",
    "import pickle\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se leen los datos y se seleccionan las variables que presentan una diferencia\n",
    "# entre los individuos que presentan estres y los que no\n",
    "data_path = Path(os.getcwd()).parent / \"data\"\n",
    "silver_path = data_path / \"silver\" / \"dreadditCleanTest.csv\"\n",
    "df = pd.read_csv(silver_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Configuracion de visualizaciones \n",
    "\n",
    "# Configurar el estilo de fondo con una cuadrícula\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Establecer una paleta de colores profesional\n",
    "sns.set_palette(['#2596be'])\n",
    "\n",
    "# Configurar la tipografía y el tamaño de la fuente\n",
    "sns.set_context(\"paper\", font_scale=1.5, rc={\"font.family\": \"sans-serif\", \"font.sans-serif\": [\"Helvetica\", \"Arial\"]})\n",
    "\n",
    "# Desactivar spines innecesarios\n",
    "sns.despine(trim=True, left=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = {}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Caracteristicas extraidas a mano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[[\"singular_pronouns\",\"adj_adv\"]]\n",
    "y = df.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_path = Path(os.getcwd()).parent / \"models\"\n",
    "\n",
    "\n",
    "# Lista para almacenar los nombres de archivos\n",
    "pkl_files = []\n",
    "\n",
    "# Recorre todos los archivos en el directorio especificado\n",
    "for filename in os.listdir(models_path):\n",
    "    if (filename.endswith('.pkl') & (\"manual\" in filename)):\n",
    "        pkl_files.append(filename)\n",
    "\n",
    "for model_name in pkl_files:\n",
    "    ruta = os.path.join(models_path,model_name)\n",
    "    # Cargar el modelo\n",
    "    with open(ruta, 'rb') as file:\n",
    "        model = pickle.load(file)\n",
    "\n",
    "    f1s= np.round(utils.evaluate_model(model, X,y).mean(),3)\n",
    "    scores[model_name.split(\".\")[0]] = f1s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solo TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(sublinear_tf=True, min_df=5,\n",
    "                        ngram_range=(1, 3), \n",
    "                        stop_words='english')\n",
    "\n",
    "features = tfidf.fit_transform(df[\"clean_text\"]).toarray()\n",
    "\n",
    "X,y = pd.DataFrame(features),df.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista para almacenar los nombres de archivos\n",
    "pkl_files = []\n",
    "\n",
    "# Recorre todos los archivos en el directorio especificado\n",
    "for filename in os.listdir(models_path):\n",
    "    if (filename.endswith('.pkl') & (\"TFIDF\" in filename)):\n",
    "        pkl_files.append(filename)\n",
    "\n",
    "for model_name in pkl_files:\n",
    "    ruta = os.path.join(models_path,model_name)\n",
    "    # Cargar el modelo\n",
    "    with open(ruta, 'rb') as file:\n",
    "        model = pickle.load(file)\n",
    "\n",
    "    f1s= np.round(utils.evaluate_model(model, X,y).mean(),3)\n",
    "    scores[model_name.split(\".\")[0]] = f1s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = tfidf.fit_transform(df[\"clean_text\"]).toarray()\n",
    "\n",
    "X,y = pd.DataFrame(features),df.label\n",
    "\n",
    "X['singular_pronouns'] = df['singular_pronouns']\n",
    "X['adj_adv'] = df['adj_adv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista para almacenar los nombres de archivos\n",
    "pkl_files = []\n",
    "\n",
    "# Recorre todos los archivos en el directorio especificado\n",
    "for filename in os.listdir(models_path):\n",
    "    if (filename.endswith('.pkl') & (\"both\" in filename)):\n",
    "        pkl_files.append(filename)\n",
    "\n",
    "for model_name in pkl_files:\n",
    "    ruta = os.path.join(models_path,model_name)\n",
    "    # Cargar el modelo\n",
    "    with open(ruta, 'rb') as file:\n",
    "        model = pickle.load(file)\n",
    "\n",
    "    f1s= np.round(utils.evaluate_model(model, X.values,y).mean(),3)\n",
    "    scores[model_name.split(\".\")[0]] = f1s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RoBERTa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmodel = os.path.join(models_path,\"saved_roberta_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model_path = rmodel\n",
    "tokenizer = RobertaTokenizer.from_pretrained(model_path)\n",
    "model = RobertaForSequenceClassification.from_pretrained(model_path)\n",
    "model.to(device);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "res= df.head(3).clean_text.apply(utils.make_prediction,args=(model,tokenizer, device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     ([[0.012544274, 0.98738015, 7.555085e-05]], [1])\n",
       "1    ([[0.0012271712, 0.9985727, 0.00020006155]], [1])\n",
       "2       ([[0.70882475, 0.29076153, 0.000413734]], [0])\n",
       "Name: clean_text, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Yesterday i went to the movies with my friends\"  # Texto de ejemplo para clasificación\n",
    "probabilities, predicted_class = utils.make_prediction(text, model, tokenizer, device)\n",
    "print(f\"Probabilidades: {probabilities}\")\n",
    "print(f\"Clase Predicha: {predicted_class}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores[\"RoBERTa\"] = 0.811"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = pd.DataFrame.from_dict(scores, orient=\"index\").reset_index()\n",
    "scores.columns=[\"model\",\"fscore\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = scores.sort_values(\"fscore\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Palabras que deben tener un color especial\n",
    "special_words = ['RoBERTa']\n",
    "\n",
    "# Función para aplicar colores\n",
    "def assign_colors(words, special_words, color_special, color_default):\n",
    "    return [color_special if word in special_words else color_default for word in words]\n",
    "\n",
    "# Colores por defecto y especial\n",
    "default_color = '#acccec'  # Azul por defecto\n",
    "special_color = '#2596be'  \n",
    "\n",
    "# Aplicar la función de asignación de colores\n",
    "colors_pal = assign_colors(scores['model'], special_words, special_color, default_color)\n",
    "\n",
    "fig, axes = plt.subplots(figsize=(12, 8))\n",
    "plt.title(\"F1-score de los diferentes modelos\")\n",
    "sns.barplot(x=\"fscore\",y=\"model\",data=scores, palette=colors_pal)\n",
    "plt.xlabel(\"F1-score\")\n",
    "plt.ylabel(\"Modelo\")\n",
    "plt.tight_layout"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
